# ALF-Bench: Customer Service Agent Benchmark

í˜„ì‹¤ì ì¸ Customer Service Agent ë²¤ì¹˜ë§ˆí¬. RAG, multi-turn ëŒ€í™”, tool ì‚¬ìš©, ê·¸ë¦¬ê³  multimodal ìƒí˜¸ì‘ìš©ì— ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤.

## ğŸ¯ ì—°êµ¬ ëª©í‘œ

ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬(TAU2, VITA)ì™€ ë‹¬ë¦¬, ì‹¤ì œ ê³ ê° ì„œë¹„ìŠ¤ í™˜ê²½ì—ì„œ ê°€ì¥ ë§ì´ ë°œìƒí•˜ëŠ” **RAG ê¸°ë°˜ ë¬¸ì˜ ì‘ëŒ€**ì— ì§‘ì¤‘:

- **RAG (Retrieval-Augmented Generation)**: ë¬¸ì„œ ê²€ìƒ‰ì„ í†µí•œ ì •í™•í•œ ë‹µë³€
- **Multi-turn Conversations**: ì‹¤ì œ ìƒë‹´ì²˜ëŸ¼ ì—¬ëŸ¬ í„´ì˜ ëŒ€í™”
- **Tool Use**: `search_data` ë„êµ¬ë¥¼ í™œìš©í•œ ë¬¸ì„œ ê²€ìƒ‰
- **Multi-modal**: í…ìŠ¤íŠ¸ë¿ë§Œ ì•„ë‹ˆë¼ ì´ë¯¸ì§€ ìº¡ì²˜ ë“± ë‹¤ì–‘í•œ ì…ë ¥ (ê³„íš)

## ğŸ“Š ì—°êµ¬ ì§ˆë¬¸

1. **ë²¤ì¹˜ë§ˆí¬ êµ¬ì¶•**: í˜„ì‹¤ì ì¸ ê³ ê° ì„œë¹„ìŠ¤ ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ì…‹
2. **ëª¨ë¸ í‰ê°€**: GPT-4, Gemini, Qwen ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ ë¹„êµ
3. **LLM-as-a-Judge ê²€ì¦**: LLMì´ í‰ê°€í•œ CSAT vs ì‹¤ì œ CSATì˜ ì‹ ë¢°ì„±
4. **ì¶”ê°€ ë³€ì¸**: ì–´ë–¤ ìš”ì†Œê°€ ë²¤ì¹˜ë§ˆí¬ ì‹ ë¢°ì„±ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ê°€?

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
alf-bench/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ domain/
â”‚       â””â”€â”€ saas/
â”‚           â””â”€â”€ channel/
â”‚               â”œâ”€â”€ docs/              # í¬ë¡¤ë§ëœ ì±„ë„í†¡ ë¬¸ì„œ (ê³„ì¸µ êµ¬ì¡°)
â”‚               â””â”€â”€ user_scenario.json # ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜
â”œâ”€â”€ crawlers/
â”‚   â””â”€â”€ channel_crawler.py             # ì±„ë„í†¡ ë¬¸ì„œ í¬ë¡¤ëŸ¬
â”œâ”€â”€ envs/
â”‚   â”œâ”€â”€ channel_env.py                 # RL-style Environment
â”‚   â”œâ”€â”€ tools.py                       # RAG tool (search_data)
â”‚   â””â”€â”€ user_simulator.py              # User ì‹œë®¬ë ˆì´í„°
â”œâ”€â”€ test_env.py                        # í™˜ê²½ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ pyproject.toml                     # í”„ë¡œì íŠ¸ ì„¤ì •
â””â”€â”€ README.md
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# Python 3.10+ í•„ìš”
uv sync

# OpenAI API í‚¤ ì„¤ì • (GPT ëª¨ë¸ ì‚¬ìš© ì‹œ)
export OPENAI_API_KEY='your-key-here'
```

### 2. ë¬¸ì„œ í¬ë¡¤ë§ (ì„ íƒì‚¬í•­)

ì´ë¯¸ í¬ë¡¤ë§ëœ ë¬¸ì„œê°€ í¬í•¨ë˜ì–´ ìˆì§€ë§Œ, ìµœì‹  ë¬¸ì„œë¥¼ ë‹¤ì‹œ í¬ë¡¤ë§í•˜ë ¤ë©´:

```bash
./run_crawler_v2.sh
```

### 3. í™˜ê²½ í…ŒìŠ¤íŠ¸

```bash
uv run python test_env.py
```

## ğŸ® Environment ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‚¬ìš©

```python
from envs import ChannelEnv

# Environment ì´ˆê¸°í™”
env = ChannelEnv(
    agent_model="gpt-4o-mini",
    user_model="gpt-4o-mini",
    max_turns=10
)

# Episode ì‹œì‘
state = env.reset(scenario_id="scenario_001")
print(f"User: {state['user_message']}")

# Agent-Environment ìƒí˜¸ì‘ìš©
done = False
while not done:
    # Agentì˜ action
    action = {
        "message": "ë‹µë³€ ë©”ì‹œì§€",
        "tool_calls": [...]  # ì„ íƒì‚¬í•­
    }
    
    # Environment step
    state, reward, done, info = env.step(action)
    
    if not done:
        print(f"User: {state['user_message']}")
```

### LiteLLM Policy ì‚¬ìš©

```python
from litellm import completion
from envs import ChannelEnv

env = ChannelEnv()
state = env.reset()

# LiteLLMìœ¼ë¡œ Agent ì •ì±… ìƒì„±
messages = [
    {"role": "system", "content": "ë‹¹ì‹ ì€ ì±„ë„í†¡ ìƒë‹´ì›ì…ë‹ˆë‹¤."},
    {"role": "user", "content": state["user_message"]}
]

response = completion(
    model="gpt-4o-mini",
    messages=messages,
    tools=env.get_available_tools(),
    temperature=0.7
)

# Policyë¥¼ actionìœ¼ë¡œ ì „ë‹¬
action = {"policy": response}
state, reward, done, info = env.step(action)
```

### RAG Tool ì‚¬ìš©

EnvironmentëŠ” ìë™ìœ¼ë¡œ `search_data` toolì„ ì œê³µí•©ë‹ˆë‹¤:

```python
tools = env.get_available_tools()
# [
#   {
#     "type": "function",
#     "function": {
#       "name": "search_data",
#       "description": "ì±„ë„í†¡ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.",
#       "parameters": {...}
#     }
#   }
# ]

# LiteLLMì´ toolì„ í˜¸ì¶œí•˜ë©´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë¨
response = completion(
    model="gpt-4o-mini",
    messages=messages,
    tools=tools
)

action = {"policy": response}
state, reward, done, info = env.step(action)
# info['tool_results']ì— ê²€ìƒ‰ ê²°ê³¼ í¬í•¨
```

## ğŸ“ ì‹œë‚˜ë¦¬ì˜¤ êµ¬ì¡°

`data/domain/saas/channel/user_scenario.json`:

```json
{
  "scenarios": [
    {
      "scenario_id": "scenario_001",
      "difficulty": "easy",
      "category": "ì±„ë„í†¡_ì„¤ì¹˜",
      "user_scenario": "User LLMì—ê²Œ ì£¼ëŠ” instruction",
      "reference_text": "Agent í‰ê°€ë¥¼ ìœ„í•œ ì •ë‹µ ë‚´ìš©",
      "source_documents": ["ì°¸ì¡° ë¬¸ì„œ ê²½ë¡œ"]
    }
  ]
}
```

## ğŸ”§ Environment API

### `ChannelEnv`

**ì´ˆê¸°í™”**:
```python
env = ChannelEnv(
    scenario_file="data/domain/saas/channel/user_scenario.json",
    docs_dir="data/domain/saas/channel/docs",
    agent_model="gpt-4o-mini",
    user_model="gpt-4o-mini",
    max_turns=10
)
```

**ë©”ì„œë“œ**:
- `reset(scenario_id=None)`: Episode ì‹œì‘, ì´ˆê¸° state ë°˜í™˜
- `step(action)`: Action ì‹¤í–‰, (state, reward, done, info) ë°˜í™˜
- `get_available_tools()`: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ë°˜í™˜
- `render(mode="human")`: í˜„ì¬ ìƒíƒœ ì¶œë ¥

**State êµ¬ì¡°**:
```python
{
    "scenario": {
        "id": "scenario_001",
        "difficulty": "easy",
        "category": "ì±„ë„í†¡_ì„¤ì¹˜"
    },
    "user_message": "ì‚¬ìš©ì ë©”ì‹œì§€",
    "conversation_history": [...],
    "turn": 3
}
```

**Action êµ¬ì¡°**:
```python
# ë°©ë²• 1: ì§ì ‘ ë©”ì‹œì§€
action = {
    "message": "ë‹µë³€ ë‚´ìš©"
}

# ë°©ë²• 2: LiteLLM policy ì‚¬ìš© (ê¶Œì¥)
action = {
    "policy": litellm_response_object
}
```

**Reward**:
- `1.0`: ì‚¬ìš©ì ë§Œì¡±, ì„±ê³µ
- `0.0`: ì¤‘ê°„ í„´
- `-1.0`: ìµœëŒ€ í„´ ë„ë‹¬, ì‚¬ìš©ì ë¶ˆë§Œì¡±

## ğŸ“š ì°¸ê³  ìë£Œ

- [ì±„ë„í†¡ ê³µì‹ ë¬¸ì„œ](https://docs.channel.io/help/ko)
- [LiteLLM ë¬¸ì„œ](https://docs.litellm.ai/)

## ğŸ”¬ í–¥í›„ ê³„íš

- [ ] ë” ë§ì€ ì‹œë‚˜ë¦¬ì˜¤ ì¶”ê°€ (í˜„ì¬ 3ê°œ â†’ 50ê°œ+)
- [ ] ì´ë¯¸ì§€ multimodal ì§€ì›
- [ ] ì‹¤ì œ CSAT ë°ì´í„° ìˆ˜ì§‘ ë° LLM-as-a-Judge ë¹„êµ
- [ ] ë‹¤ì–‘í•œ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ê³µê°œ
- [ ] ë‹¤ë¥¸ ë„ë©”ì¸(e-commerce, SaaS ë“±) í™•ì¥

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ‘¥ Contributors

- Seungyoun Shin (robin@channel.io)
